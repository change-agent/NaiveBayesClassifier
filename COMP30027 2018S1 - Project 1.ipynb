{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2018 Semester 1\n",
    "-----\n",
    "## Project 1: What is labelled data worth to Naive Bayes?\n",
    "-----\n",
    "###### Student Name(s): Daniel Masters (583334)\n",
    "###### Python version: 3\n",
    "-----\n",
    "## N.B. \n",
    "\n",
    "- I implemented the functions with three datasets in mind: *breast-cancer*, *mushroom*, *hypothyroid*. You can test each of them by modifying the filename variable at the start of the *preprocess* functions. \n",
    "\n",
    "- You can test the hold-out functionality by modifying the *hold_out_percent* variable in the preprocess_supervised function.\n",
    "\n",
    "- I have also attached the 2 individual iPython notebooks where you can run the programs as iPython scripts, if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "def preprocess_supervised():\n",
    "    import pandas as pd\n",
    "    import math\n",
    "    from collections import defaultdict\n",
    "\n",
    "    #Convert CSV to dataframe; slice into two dataframes based on class\n",
    "\n",
    "    # Select from breast-cancer, mushroom, hypothyroid. Enter hold-out percentage.\n",
    "    filename = 'breast-cancer-dos.csv'\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    hold_out_percent = 0\n",
    "\n",
    "    num_rows = len(df)\n",
    "    df_len = len(df.columns) - 1\n",
    "    classes_list = df[df_len].unique()\n",
    "    num_class = len(classes_list)\n",
    "    hold_outs_index = math.ceil(len(df) - hold_out_percent*num_rows)\n",
    "    hold_outs = df.iloc[hold_outs_index:len(df),:]\n",
    "    df = df.iloc[0:hold_outs_index,:]\n",
    "    num_instances = len(df)\n",
    "    class1 = df[df[df_len] == str(classes_list[0])]\n",
    "    class2 = df[df[df_len] == str(classes_list[1])]\n",
    "    del class1[df_len]\n",
    "    del class2[df_len]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should build a supervised NB model\n",
    "def train_supervised():\n",
    "    \n",
    "    #Generate attribute instance frequencies for both classes\n",
    "    class1_freq = [dict() for x in class1]\n",
    "    class2_freq = [dict() for x in class2]\n",
    "\n",
    "    for i in class1:\n",
    "        class1_freq[i] = defaultdict(int)\n",
    "        for key in class1[i]:\n",
    "            class1_freq[i][key] += 1\n",
    "\n",
    "    for i in class2:\n",
    "        class2_freq[i] = defaultdict(int)\n",
    "        for key in class2[i]:\n",
    "            class2_freq[i][key] += 1\n",
    "\n",
    "    #Generate posterior probabilities and apply log-transformation - i.e. log(P(Xi|Cj))\n",
    "    class1_posterior = [dict() for x in class1_freq]\n",
    "    class2_posterior = [dict() for x in class2_freq]\n",
    "\n",
    "    for i in class1:\n",
    "        total_class1 = sum(class1_freq[i].values(), 0.0)\n",
    "        class1_posterior[i][i] = {k: math.log10(v/total_class1) for k, v in class1_freq[i].items()}\n",
    "\n",
    "    for i in class2:\n",
    "        total_class2 = sum(class2_freq[i].values(), 0.0)\n",
    "        class2_posterior[i][i]  = {k: math.log10(v/total_class2) for k, v in class2_freq[i].items()}\n",
    "\n",
    "    #Generate class probabilities and apply log-transformation - i.e. log(P(Cj))\n",
    "    class1_prob = math.log10(total_class1/num_instances)\n",
    "    class2_prob = math.log10(total_class2/num_instances)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict the class for a set of instances, based on a trained model \n",
    "def predict_supervised():\n",
    "    class1_predicted = defaultdict(int)\n",
    "    class2_predicted = defaultdict(int)\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(num_rows-hold_outs_index, num_instances):\n",
    "        for j in range(len(class1.columns)):\n",
    "            try:\n",
    "                class2_predicted[i] += class2_posterior[j][j][df[j][i]]\n",
    "                class1_predicted[i] += class1_posterior[j][j][df[j][i]]\n",
    "\n",
    "            #Allow for any attributes that are present in only one class dictionary\n",
    "            except KeyError:\n",
    "                class2_predicted[i] += 0\n",
    "                class1_predicted[i] += 0\n",
    "        class2_predicted[i] += class2_prob\n",
    "        class1_predicted[i] += class1_prob\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in a supervised context \n",
    "def evaluate_supervised():\n",
    "    for i in range(num_rows-hold_outs_index, num_instances):\n",
    "        if(class1_predicted[i] >= class2_predicted[i]):\n",
    "            if(df[df_len][i]==str(classes_list[0])):\n",
    "                correct += 1\n",
    "        elif(class1_predicted[i] < class2_predicted[i]):\n",
    "            if(df[df_len][i]==str(classes_list[1])):\n",
    "                correct += 1\n",
    "            \n",
    "    print(\"Accuracy: \" + str(round(correct*100/num_instances, 2)) + \"%\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "def preprocess_unsupervised():     \n",
    "    import pandas as pd\n",
    "    import math\n",
    "    import random\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    # Convert CSV to dataframe\n",
    "    \n",
    "    # Select from breast-cancer, mushroom, hypothyroid\n",
    "    filename = 'breast-cancer-dos.csv'\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "\n",
    "    class1 = class2 = 0\n",
    "    df_len = len(df.columns) - 1\n",
    "    classes_list = df[df_len].unique()\n",
    "    num_classes = len(classes_list)\n",
    "    num_instances = len(df)\n",
    "    attributes_len = df_len - num_classes\n",
    "    labelled_data = df[df_len].copy(deep=True)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should build an unsupervised NB model \n",
    "def train_unsupervised():\n",
    "    for i in range(num_instances): \n",
    "        df.at[i, df_len-1] = random.uniform(0, 1)\n",
    "        df.at[i, df_len] = 1 - df[df_len-1][i]\n",
    "        class1 += df.at[i, df_len-1] \n",
    "        class2 += df.at[i, df_len]\n",
    "\n",
    "    # Generate attribute instance frequencies for both classes\n",
    "    reccurence_freq = [dict() for x in range(attributes_len)]\n",
    "    no_reccurence_freq = [dict() for x in range(attributes_len)]\n",
    "\n",
    "    for i in range(attributes_len):\n",
    "        reccurence_freq[i] = defaultdict(int)\n",
    "        for j in range(num_instances):\n",
    "            reccurence_freq[i][df[i][j]] += df[df_len-1][j]\n",
    "\n",
    "    for i in range(attributes_len):\n",
    "        no_reccurence_freq[i] = defaultdict(int)\n",
    "        for j in range(num_instances):\n",
    "            no_reccurence_freq[i][df[i][j]] += df[df_len][j]\n",
    "\n",
    "    for i in range(attributes_len):\n",
    "        for key in reccurence_freq[i]:\n",
    "            reccurence_freq[i][key] = reccurence_freq[i][key]/class1\n",
    "\n",
    "    for i in range(attributes_len):\n",
    "        for key in no_reccurence_freq[i]:\n",
    "            no_reccurence_freq[i][key] = no_reccurence_freq[i][key]/class2\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict the class distribution for a set of instances, based on a trained model\n",
    "def predict_unsupervised():\n",
    "\n",
    "# N.B. I realise this is not the most efficient algorithm -- I was having trouble getting it to work since I'm not very familiar\n",
    "# with Python, so I designed the algorithm to replicate each step of the process as a \"visualised\" sanity check of sorts.\n",
    "\n",
    "    prediction = [defaultdict(int) for x in range(num_instances)]\n",
    "    prediction2 = [defaultdict(int) for x in range(num_instances)]\n",
    "    num_iterations = 4\n",
    "    true_positive = true_negative = false_negative = false_positive = 0\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        if iteration == 0:\n",
    "            for i in range(num_instances):\n",
    "                for j in range(attributes_len):\n",
    "                    prediction[i][df[j][i]] = reccurence_freq[j][df[j][i]]\n",
    "                    prediction[i]['temp'] = 1\n",
    "\n",
    "            for i in range(num_instances):\n",
    "                for j in range(attributes_len):\n",
    "                    prediction2[i][df[j][i]] = no_reccurence_freq[j][df[j][i]]\n",
    "                    prediction2[i]['temp'] = 1\n",
    "\n",
    "        for i in range(num_instances):\n",
    "            for j in range(attributes_len):\n",
    "                prediction[i]['temp'] *= prediction[i][df[j][i]]\n",
    "            prediction[i]['pred'] = 1\n",
    "            prediction[i]['pred'] *= class1/num_instances\n",
    "            prediction[i]['pred'] *= prediction[i]['temp']\n",
    "\n",
    "        for i in range(num_instances):\n",
    "            for j in range(attributes_len):\n",
    "                prediction2[i]['temp'] *= prediction2[i][df[j][i]]\n",
    "            prediction2[i]['pred'] = 1\n",
    "            prediction2[i]['pred'] *= class2/num_instances\n",
    "            prediction2[i]['pred'] *= prediction2[i]['temp']\n",
    "\n",
    "        for i in range(num_instances):\n",
    "            prediction[i]['newclass'] = prediction[i]['pred']/(prediction[i]['pred']+prediction2[i]['pred'])\n",
    "            prediction2[i]['newclass'] = prediction2[i]['pred']/(prediction[i]['pred']+prediction2[i]['pred'])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in an unsupervised manner\n",
    "def evaluate_unsupervised():\n",
    "    for i in range(num_instances):        \n",
    "        if(prediction[i]['newclass'] >= prediction2[i]['newclass']):\n",
    "            if(labelled_data[i]==str(classes_list[0])):\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "        elif(prediction[i]['newclass'] < prediction2[i]['newclass']):\n",
    "            if(labelled_data[i]==str(classes_list[1])):\n",
    "                true_negative += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "\n",
    "    print(\"Accuracy: \" + str(round((true_positive+true_negative)*100/num_instances, 2)) + \"%\\n\")\n",
    "\n",
    "    print(\"CONFUSION MATRIX\\nTrue Positive:  \" + str(true_positive) + \"     True Negative: \" + str(true_negative) \n",
    "          + \"\\nFalse Negative: \" + str(false_negative) + \"     False Positive: \" + str(false_positive))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Each of the datasets have numerous similar or duplicated instances, which means the posterior probabilities are high for many of the attributes and means the data is less noisy. In turn, this causes highly skewed predictions, resulting in the mentioned variation in accuracy (\"pretty good\" vs \"utter fail\"). Of particular note, I observed relatively high accuracy from the hypothyroid dataset, which has very similar instances throughout. \n",
    "\n",
    "Further evidence supporting this hypothesis: when accuracy has been below 50%, the confusion matrix has consistently shown a skew towards false positives, rather than a relatively equal spread between false positives and false negatives.\n",
    "\n",
    "### Question 3\n",
    "\n",
    "I observed a reduction in accuracy for each dataset when implementing a hold-out evaluation strategy. This is expected behaviour, since evaluating the model using the training data is essentially just checking how well it can recall data, rather than its ability to predict unknown data. Each dataset exhibited relatively similar reductions, depending on the hold-out percentage:\n",
    "\n",
    "|          | Hypothyroid | Breast Cancer | Mushroom |\n",
    "|----------|-------------|---------------|----------|\n",
    "| Original | 93.17%      | 73.43%        | 84.91%   |\n",
    "| 10%      | 86.83%      | 67.55%        | 75.30%   |\n",
    "| 20%      | 73.29%      | 55.02%        | 64.18%   |\n",
    "| 50%      | 0.06%       | 0.00%         | 0.00%    |\n",
    "\n",
    "Surprisingly, a 50% hold-out resulted in a steep decline in accuracy. Otherwise, the differences are as expected, and largely similar across the dataset:\n",
    "\n",
    "|     | Hypothyroid | Breast Cancer | Mushroom |\n",
    "|-----|-------------|---------------|----------|\n",
    "| 10% | -6.34%       | -5.88%         | -9.61%    |\n",
    "| 20% | -19.88%      | -18.41%        | -20.73%   |\n",
    "| 50% | -93.11%      | -73.43%        | -84.91%   |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
